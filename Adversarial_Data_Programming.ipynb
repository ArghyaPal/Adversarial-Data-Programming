{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial_Data_Programming.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PfRQX1nCH4QH0B5Uff_Qzz7lUwjDCM04",
      "authorship_tag": "ABX9TyML9ygQe0tyno77KOVNe/cJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArghyaPal/Adversarial_Data_Programming/blob/master/Adversarial_Data_Programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZEmJOpFtYhN",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Data Programming\n",
        "Paucity of large curated hand-labeled training data forms a major bottleneck in the deployment of machine learning models in computer vision and other fields. Recent work (Data Programming) has shown how distant supervision signals in the form of labeling functions can be used to obtain labels for given data in near-constant time. In this work, we present Adversarial Data Programming (ADP), which presents an adversarial methodology to generate data as well as a curated aggregated label, given a set of weak labeling functions. We validated our method on the MNIST, Fashion MNIST, CIFAR10 and SVHN datasets, and it outperformed many state-of-the-art models. We conducted extensive experiments to study its usefulness, as well as showed how the proposed ADP framework can be used for transfer learning as well as multi-task learning, where data from two domains are generated simultaneously using the framework along with the label information. Our future work will involve understanding the theoretical implications of this new framework from a game-theoretic perspective, as well as explore the performance of the method on more complex datasets.\n",
        "\n",
        "**TL;DR:**<br>\n",
        "Learning the parameters of Joint Distribution, i.e. $P(Χ, y)$ and $Χ$: image, $y$: label, using Distant Supervision Signals. In this work, we seek to learn the parameters of the Joint Distribution $P(Χ, LFB_{(L, θ, φ)}(X))$. The $LFB_{(L, θ, φ)} (.)$ acts as a proxy to the real label y. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP3xDdKxMDnM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d8fc07e-adc9-4f2d-a481-0e604c88a33a"
      },
      "source": [
        "# Please run it once on a runtime\n",
        "!pip install kmeans-pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kmeans-pytorch in /usr/local/lib/python3.6/dist-packages (0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5HmixuLKuwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import numpy as np\n",
        "from kmeans_pytorch import kmeans, kmeans_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyyWXMNpM0w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decide which device we want to run on\n",
        "ngpu = 4\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK2xHmM4K1mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Hyperparameters used in this projects\n",
        "'''\n",
        "# The noise dimension for the Generator, i.e. the z dimension, sampled from a Gaussian Distribution\n",
        "latent_size = 64\n",
        "# The network layer dimension of Generator and Discriminator\n",
        "hidden_size = 256\n",
        "# The generated image size/image size. MNIST size 28 X 28 = 784\n",
        "image_size = 784\n",
        "# Number of epochs\n",
        "num_epochs = 300\n",
        "# A mini-batch size\n",
        "batch_size = 20\n",
        "# Adam learning rate\n",
        "lr = 0.0001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjsGaQxmHMui",
        "colab_type": "text"
      },
      "source": [
        "### Please mention the number of Labeleing Functions here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD1x0b2aHEtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gZ0G-2oH0BK",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPedqD1nK4vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_dir = 'samples'\n",
        "save_dir = 'save'\n",
        "\n",
        "# Create a directory if not exists\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Image processing\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=(0.5),   # 3 for RGB channels\n",
        "                                     std=(0.5))])\n",
        "\n",
        "# MNIST dataset\n",
        "mnist = torchvision.datasets.MNIST(root='./data/',\n",
        "                                   train=True,\n",
        "                                   transform=transform,\n",
        "                                   download=True)\n",
        "\n",
        "# Data loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpE1mtRn__m0",
        "colab_type": "text"
      },
      "source": [
        "### ADP Labeling Function Block $LFB(y|X, \\Theta)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0OYu7dJ0GKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    \"\"\"\n",
        "    The labeling functions infer label of an image independently \n",
        "    (i.e. independent decision assumption) and the parameter gives relative \n",
        "    weight to each of the labeling functions based on their correctness of \n",
        "    inferred label for true class y.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X\n",
        "        Batch of images, torch.Tensor\n",
        "    theta\n",
        "        Batch of relative accuracies are weights given to labeling functions \n",
        "        based on whether their outputs agree with true class label y of an \n",
        "        image X, torch.Tensor\n",
        "    Returns\n",
        "    -------\n",
        "    theta * y1\n",
        "        Batch of approximated labels (in this formulation), torch.Tensor\n",
        "    \"\"\"\n",
        "def lf1(fake_images, theta): \n",
        "  # fake_images is a batch of generated images from the G_image\n",
        "  cluster_centers = torch.load('/content/drive/My Drive/Colab_Notebooks/cluster_centers.pt')\n",
        "  # we use k-means (unsupervised) clustering as one labeling function\n",
        "  y1 = kmeans_predict(fake_images, cluster_centers, 'euclidean', device=device)\n",
        "  y1 = y1.view(-1,1).cuda()\n",
        "  return theta * y1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsci7azICCBv",
        "colab_type": "text"
      },
      "source": [
        "### ADP Generator $G(X, \\Theta|z)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyl-RaOiLM1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.G_common = nn.Sequential(\n",
        "                              nn.Linear(latent_size, hidden_size),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Linear(hidden_size, hidden_size),\n",
        "                              nn.ReLU())\n",
        "        self.G_image = nn.Sequential(\n",
        "                              nn.Linear(hidden_size, image_size),\n",
        "                              nn.Tanh())\n",
        "        self.G_parameter = nn.Sequential(\n",
        "                              nn.Linear(hidden_size, theta),\n",
        "                              # We use softmax to make the theta to be in the \n",
        "                              # range [0,1]\n",
        "                              nn.Softmax(dim=1))\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    z\n",
        "        Batch of noise vector, torch.Tensor\n",
        "    Returns\n",
        "    -------\n",
        "    X\n",
        "        Batch of images, torch.Tensor\n",
        "    theta\n",
        "        Batch of a Relative accuracies, torch.Tensor\n",
        "    \"\"\"\n",
        "    def forward(self, input):\n",
        "        common = self.G_common(input)\n",
        "        image = self.G_image(common)\n",
        "        theta = self.G_parameter(common)\n",
        "        return image, theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbZng0nN1HHe",
        "colab_type": "text"
      },
      "source": [
        "### ADP Discriminator D(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58NhqczSLKTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  '''\n",
        "  The discriminator class takes a batch of either real or generated image and \n",
        "  inferred label from Labeling Functions Block LFB(.) pairs as input.\n",
        "  And, maps that to a probability score to estimate the aforementioned \n",
        "  likelihood of the image-label pair as real labeled-image\n",
        "  '''\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        '''\n",
        "        The D_image takes a batch of images\n",
        "        '''\n",
        "        self.D_image = nn.Sequential(\n",
        "                              nn.Linear(image_size, hidden_size),\n",
        "                              nn.LeakyReLU(0.2))\n",
        "        '''\n",
        "        The D_label takes a batch of labels\n",
        "        '''\n",
        "        self.D_label = nn.Sequential(\n",
        "                              nn.Linear(10, hidden_size),\n",
        "                              nn.LeakyReLU(0.2))\n",
        "        '''\n",
        "        The D_common adds the D_image and D_label branches and provides \n",
        "        '''\n",
        "        self.D_common = nn.Sequential(\n",
        "                              nn.Linear(hidden_size*2, hidden_size),\n",
        "                              nn.LeakyReLU(0.2),\n",
        "                              nn.Linear(hidden_size, 1),\n",
        "                              # This will ensure the output to be in the range of [0,1]\n",
        "                              nn.Sigmoid())\n",
        "    \"\"\"Estimates the probability score as a likelihood of the input image-label pair\n",
        "    as real image-label pair.\n",
        "    This function provides a batch of probability scores, i.e. P(X, y), stored as a \n",
        "    vector P. We will use that vector to give loss signal to the Discriminator D(.) \n",
        "    and Generator G(.).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X\n",
        "        Batch of images, torch.Tensor\n",
        "    y\n",
        "        Batch of labels, torch.Tensor\n",
        "    Returns\n",
        "    -------\n",
        "    result\n",
        "        Batch of probabilities, torch.Tensor\n",
        "    \"\"\"\n",
        "    def forward(self, image, label):\n",
        "        # image is the batch of images given to the D_image branch\n",
        "        image = self.D_image(image)\n",
        "        # label is the corresponding labels given to the D_label branch\n",
        "        label = self.D_label(label)\n",
        "        # common is the branch that concates D_image and D_label\n",
        "        common = torch.cat([image, label], 1)\n",
        "        # result is the batch of probability score\n",
        "        result = self.D_common(common)\n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlfNq55ULRuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device setting\n",
        "G = Generator().cuda()\n",
        "D = Discriminator().cuda()\n",
        "\n",
        "# Binary cross entropy loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=lr)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=lr)\n",
        "\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "def reset_grad():\n",
        "    d_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFY03OEhLWKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Statistics to be saved\n",
        "d_losses = np.zeros(num_epochs)\n",
        "g_losses = np.zeros(num_epochs)\n",
        "real_scores = np.zeros(num_epochs)\n",
        "fake_scores = np.zeros(num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9TM5beFLhi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d6dbac1-f5b5-4565-9ca8-0473ef458af9"
      },
      "source": [
        "# We will start Adversarial Data Programming training\n",
        "total_step = len(data_loader)\n",
        "\n",
        "# To change num_epochhs please visit the hyperparameters section\n",
        "for epoch in range(num_epochs):\n",
        "  # We will be training discriminator one time and then the generator one time\n",
        "  # using the for loop\n",
        "    for i, (images, original_labels) in enumerate(data_loader):\n",
        "\n",
        "        # Reading real MNIST images\n",
        "        images = images.view(batch_size, -1).cuda()\n",
        "        images = Variable(images)\n",
        "        # Reading real MNIST labeles of the corresponding images\n",
        "        original_labels = torch.nn.functional.one_hot(original_labels, num_classes=10)\n",
        "        # We are making it in one-hot encoding\n",
        "        original_labels = original_labels.view(batch_size, -1).cuda()\n",
        "        original_labels = Variable(original_labels).float()\n",
        "        \n",
        "\n",
        "        # Labels for the discriminator. Real Labels are 1 and Fake Labels are 0\n",
        "        real_labels = torch.ones(batch_size, 1).cuda()\n",
        "        real_labels = Variable(real_labels)\n",
        "        fake_labels = torch.zeros(batch_size, 1).cuda()\n",
        "        fake_labels = Variable(fake_labels)\n",
        "\n",
        "        #######################################################################\n",
        "        '''\n",
        "        Below line of codes will train the discriminator.\n",
        "        The discriminator will take: (i) a batch of images; and (ii) a batch of labels\n",
        "        The object, i.e. outputs = D(images, original_labels), of the Discriminator class\n",
        "        We compute BCE_Loss using real images where:\n",
        "        BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
        "        Second term of the loss is always zero since real_labels == 1\n",
        "        '''\n",
        "        outputs = D(images, original_labels)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "        #######################################################################\n",
        "\n",
        "        #######################################################################\n",
        "        '''\n",
        "        We sample z from the Isotropic Gaussian distribution\n",
        "        Compute BCELoss using fake images\n",
        "        First term of the loss is always zero since fake_labels == 0\n",
        "        '''\n",
        "        z = torch.randn(batch_size, latent_size).cuda()\n",
        "        z = Variable(z)\n",
        "        # We put that in the G_common\n",
        "        fake_images, theta = G(z)\n",
        "\n",
        "        # generated labels from labeling function (here, we are showing one labeling function)\n",
        "        gen_labels = lf1(fake_images, theta)\n",
        "        gen_labels = gen_labels.view(20)\n",
        "        gen_labels = torch.nn.functional.one_hot(gen_labels.to(torch.int64), num_classes=10).float()\n",
        "        # \n",
        "        outputs = D(fake_images, gen_labels)\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        fake_score = outputs\n",
        "        \n",
        "        # Backprop and optimize\n",
        "        # If D is trained so well, then don't update\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        reset_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        #######################################################################\n",
        "\n",
        "        '''\n",
        "        Train generator \n",
        "        '''\n",
        "\n",
        "        # Compute loss with fake images\n",
        "        z = torch.randn(batch_size, latent_size).cuda()\n",
        "        z = Variable(z)\n",
        "        fake_images, theta = G(z)\n",
        "        gen_labels = lf1(fake_images, theta)\n",
        "        gen_labels = gen_labels.view(batch_size)\n",
        "        gen_labels = torch.nn.functional.one_hot(gen_labels.to(torch.int64), num_classes=10).float()\n",
        "        # \n",
        "        outputs = D(fake_images, gen_labels)\n",
        "        \n",
        "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
        "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        \n",
        "        # Backprop and optimize\n",
        "        # if G is trained so well, then don't update\n",
        "        reset_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "\n",
        "         #=================================================================== #\n",
        "        #                          Update Statistics                          #\n",
        "        # =================================================================== #\n",
        "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) + d_loss.data*(1./(i+1.))\n",
        "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) + g_loss.data*(1./(i+1.))\n",
        "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) + real_score.mean().data*(1./(i+1.))\n",
        "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) + fake_score.mean().data*(1./(i+1.))\n",
        "\n",
        "\n",
        "        if (i+1) % 200 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "                  .format(epoch, num_epochs, i+1, total_step, d_loss.data, g_loss.data, \n",
        "                          real_score.mean().data, fake_score.mean().data))\n",
        "            \n",
        "    # Save real images\n",
        "    if (epoch+1) == 1:\n",
        "        images = images.view(images.size(0), 1, 28, 28)\n",
        "        save_image(denorm(images.data), os.path.join(sample_dir, 'real_images.png'))\n",
        "    \n",
        "    # Save sampled images\n",
        "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
        "    print(gen_labels)\n",
        "    save_image(denorm(fake_images.data), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
        "    \n",
        "    # Save and plot Statistics\n",
        "    np.save(os.path.join(save_dir, 'd_losses.npy'), d_losses)\n",
        "    np.save(os.path.join(save_dir, 'g_losses.npy'), g_losses)\n",
        "    np.save(os.path.join(save_dir, 'fake_scores.npy'), fake_scores)\n",
        "    np.save(os.path.join(save_dir, 'real_scores.npy'), real_scores)\n",
        "    \n",
        "    plt.figure()\n",
        "    pylab.xlim(0, num_epochs + 1)\n",
        "    plt.plot(range(1, num_epochs + 1), d_losses, label='d loss')\n",
        "    plt.plot(range(1, num_epochs + 1), g_losses, label='g loss')    \n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_dir, 'loss.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    pylab.xlim(0, num_epochs + 1)\n",
        "    pylab.ylim(0, 1)\n",
        "    plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
        "    plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_dir, 'accuracy.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "    # Save model at checkpoints\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        torch.save(G.state_dict(), os.path.join(save_dir, 'G--{}.ckpt'.format(epoch+1)))\n",
        "        torch.save(D.state_dict(), os.path.join(save_dir, 'D--{}.ckpt'.format(epoch+1)))\n",
        "\n",
        "# Save the model checkpoints \n",
        "torch.save(G.state_dict(), 'G.ckpt')\n",
        "torch.save(D.state_dict(), 'D.ckpt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/300], Step [200/3000], d_loss: 0.3913, g_loss: 4.5863, D(x): 0.97, D(G(z)): 0.24\n",
            "Epoch [0/300], Step [400/3000], d_loss: 0.0727, g_loss: 4.7496, D(x): 0.97, D(G(z)): 0.02\n",
            "Epoch [0/300], Step [600/3000], d_loss: 0.1569, g_loss: 5.6661, D(x): 0.95, D(G(z)): 0.02\n",
            "Epoch [0/300], Step [800/3000], d_loss: 0.2424, g_loss: 6.4872, D(x): 0.91, D(G(z)): 0.04\n",
            "Epoch [0/300], Step [1000/3000], d_loss: 0.2634, g_loss: 4.3639, D(x): 0.99, D(G(z)): 0.07\n",
            "Epoch [0/300], Step [1200/3000], d_loss: 0.1355, g_loss: 3.2382, D(x): 0.96, D(G(z)): 0.03\n",
            "Epoch [0/300], Step [1400/3000], d_loss: 0.0972, g_loss: 5.6429, D(x): 0.96, D(G(z)): 0.01\n",
            "Epoch [0/300], Step [1600/3000], d_loss: 0.2605, g_loss: 3.4289, D(x): 0.94, D(G(z)): 0.11\n",
            "Epoch [0/300], Step [1800/3000], d_loss: 0.0660, g_loss: 4.2444, D(x): 0.97, D(G(z)): 0.03\n",
            "Epoch [0/300], Step [2000/3000], d_loss: 0.0392, g_loss: 4.2151, D(x): 1.00, D(G(z)): 0.04\n",
            "Epoch [0/300], Step [2200/3000], d_loss: 0.1175, g_loss: 3.7520, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [0/300], Step [2400/3000], d_loss: 0.1873, g_loss: 4.8393, D(x): 0.95, D(G(z)): 0.04\n",
            "Epoch [0/300], Step [2600/3000], d_loss: 0.2038, g_loss: 3.8524, D(x): 1.00, D(G(z)): 0.16\n",
            "Epoch [0/300], Step [2800/3000], d_loss: 0.3032, g_loss: 3.8596, D(x): 0.89, D(G(z)): 0.02\n",
            "Epoch [0/300], Step [3000/3000], d_loss: 0.1822, g_loss: 4.1341, D(x): 0.96, D(G(z)): 0.08\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
            "Epoch [1/300], Step [200/3000], d_loss: 0.4514, g_loss: 3.5133, D(x): 0.86, D(G(z)): 0.04\n",
            "Epoch [1/300], Step [400/3000], d_loss: 0.5931, g_loss: 3.1978, D(x): 0.88, D(G(z)): 0.11\n",
            "Epoch [1/300], Step [600/3000], d_loss: 0.2710, g_loss: 3.3974, D(x): 0.88, D(G(z)): 0.02\n",
            "Epoch [1/300], Step [800/3000], d_loss: 0.4564, g_loss: 3.5056, D(x): 0.87, D(G(z)): 0.06\n",
            "Epoch [1/300], Step [1000/3000], d_loss: 0.2939, g_loss: 5.1383, D(x): 0.93, D(G(z)): 0.08\n",
            "Epoch [1/300], Step [1200/3000], d_loss: 0.2713, g_loss: 4.7435, D(x): 0.92, D(G(z)): 0.03\n",
            "Epoch [1/300], Step [1400/3000], d_loss: 0.2584, g_loss: 6.0723, D(x): 0.91, D(G(z)): 0.02\n",
            "Epoch [1/300], Step [1600/3000], d_loss: 0.3614, g_loss: 2.3999, D(x): 1.00, D(G(z)): 0.18\n",
            "Epoch [1/300], Step [1800/3000], d_loss: 0.0576, g_loss: 5.3656, D(x): 0.99, D(G(z)): 0.04\n",
            "Epoch [1/300], Step [2000/3000], d_loss: 0.0176, g_loss: 4.5168, D(x): 1.00, D(G(z)): 0.01\n",
            "Epoch [1/300], Step [2200/3000], d_loss: 0.2885, g_loss: 6.2701, D(x): 0.89, D(G(z)): 0.00\n",
            "Epoch [1/300], Step [2400/3000], d_loss: 0.0559, g_loss: 5.7154, D(x): 1.00, D(G(z)): 0.04\n",
            "Epoch [1/300], Step [2600/3000], d_loss: 0.0156, g_loss: 6.6006, D(x): 0.99, D(G(z)): 0.00\n",
            "Epoch [1/300], Step [2800/3000], d_loss: 0.0926, g_loss: 3.6255, D(x): 0.98, D(G(z)): 0.06\n",
            "Epoch [1/300], Step [3000/3000], d_loss: 0.0251, g_loss: 4.4282, D(x): 0.99, D(G(z)): 0.02\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
            "Epoch [2/300], Step [200/3000], d_loss: 0.1374, g_loss: 3.8805, D(x): 1.00, D(G(z)): 0.12\n",
            "Epoch [2/300], Step [400/3000], d_loss: 0.0931, g_loss: 5.0280, D(x): 0.99, D(G(z)): 0.06\n",
            "Epoch [2/300], Step [600/3000], d_loss: 0.1577, g_loss: 6.0288, D(x): 0.95, D(G(z)): 0.01\n",
            "Epoch [2/300], Step [800/3000], d_loss: 0.0943, g_loss: 5.3604, D(x): 0.97, D(G(z)): 0.04\n",
            "Epoch [2/300], Step [1000/3000], d_loss: 0.2001, g_loss: 5.3056, D(x): 0.93, D(G(z)): 0.00\n",
            "Epoch [2/300], Step [1200/3000], d_loss: 0.0838, g_loss: 3.5858, D(x): 0.97, D(G(z)): 0.03\n",
            "Epoch [2/300], Step [1400/3000], d_loss: 0.1166, g_loss: 4.8226, D(x): 0.98, D(G(z)): 0.07\n",
            "Epoch [2/300], Step [1600/3000], d_loss: 0.1421, g_loss: 3.4942, D(x): 0.96, D(G(z)): 0.04\n",
            "Epoch [2/300], Step [1800/3000], d_loss: 0.2478, g_loss: 5.6285, D(x): 0.92, D(G(z)): 0.04\n",
            "Epoch [2/300], Step [2000/3000], d_loss: 0.2001, g_loss: 5.2711, D(x): 0.96, D(G(z)): 0.09\n",
            "Epoch [2/300], Step [2200/3000], d_loss: 0.0956, g_loss: 5.4972, D(x): 0.94, D(G(z)): 0.02\n",
            "Epoch [2/300], Step [2400/3000], d_loss: 0.4429, g_loss: 7.1354, D(x): 0.86, D(G(z)): 0.00\n",
            "Epoch [2/300], Step [2600/3000], d_loss: 0.3553, g_loss: 4.4809, D(x): 0.91, D(G(z)): 0.02\n",
            "Epoch [2/300], Step [2800/3000], d_loss: 0.2169, g_loss: 4.5888, D(x): 0.91, D(G(z)): 0.02\n",
            "Epoch [2/300], Step [3000/3000], d_loss: 0.1249, g_loss: 3.7659, D(x): 0.96, D(G(z)): 0.03\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
            "Epoch [3/300], Step [200/3000], d_loss: 0.4066, g_loss: 4.5413, D(x): 0.96, D(G(z)): 0.16\n",
            "Epoch [3/300], Step [400/3000], d_loss: 0.0059, g_loss: 6.4799, D(x): 1.00, D(G(z)): 0.01\n",
            "Epoch [3/300], Step [600/3000], d_loss: 0.1072, g_loss: 4.9668, D(x): 0.96, D(G(z)): 0.02\n",
            "Epoch [3/300], Step [800/3000], d_loss: 0.3419, g_loss: 5.5081, D(x): 0.90, D(G(z)): 0.00\n",
            "Epoch [3/300], Step [1000/3000], d_loss: 0.1538, g_loss: 4.6142, D(x): 0.93, D(G(z)): 0.03\n",
            "Epoch [3/300], Step [1200/3000], d_loss: 0.4724, g_loss: 3.5879, D(x): 0.90, D(G(z)): 0.03\n",
            "Epoch [3/300], Step [1400/3000], d_loss: 0.0833, g_loss: 4.6594, D(x): 0.95, D(G(z)): 0.01\n",
            "Epoch [3/300], Step [1600/3000], d_loss: 0.0249, g_loss: 4.1272, D(x): 1.00, D(G(z)): 0.02\n",
            "Epoch [3/300], Step [1800/3000], d_loss: 0.3159, g_loss: 3.4806, D(x): 0.88, D(G(z)): 0.10\n",
            "Epoch [3/300], Step [2000/3000], d_loss: 0.2794, g_loss: 4.9805, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [3/300], Step [2200/3000], d_loss: 0.2101, g_loss: 3.9423, D(x): 0.94, D(G(z)): 0.08\n",
            "Epoch [3/300], Step [2400/3000], d_loss: 0.1358, g_loss: 3.6736, D(x): 0.95, D(G(z)): 0.03\n",
            "Epoch [3/300], Step [2600/3000], d_loss: 0.2189, g_loss: 3.5083, D(x): 0.92, D(G(z)): 0.08\n",
            "Epoch [3/300], Step [2800/3000], d_loss: 0.1429, g_loss: 3.5024, D(x): 0.98, D(G(z)): 0.10\n",
            "Epoch [3/300], Step [3000/3000], d_loss: 0.2534, g_loss: 4.1694, D(x): 0.98, D(G(z)): 0.13\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
            "Epoch [4/300], Step [200/3000], d_loss: 0.0691, g_loss: 5.2447, D(x): 0.95, D(G(z)): 0.01\n",
            "Epoch [4/300], Step [400/3000], d_loss: 0.4127, g_loss: 5.8288, D(x): 0.89, D(G(z)): 0.02\n",
            "Epoch [4/300], Step [600/3000], d_loss: 0.2137, g_loss: 3.2876, D(x): 0.95, D(G(z)): 0.10\n",
            "Epoch [4/300], Step [800/3000], d_loss: 0.2104, g_loss: 3.3956, D(x): 0.96, D(G(z)): 0.12\n",
            "Epoch [4/300], Step [1000/3000], d_loss: 0.2102, g_loss: 3.8968, D(x): 0.92, D(G(z)): 0.06\n",
            "Epoch [4/300], Step [1200/3000], d_loss: 0.1968, g_loss: 3.5522, D(x): 0.92, D(G(z)): 0.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-52122c8ec411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \"\"\"\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}