{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generalized_Adversarial_Data_Programming.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "171_HrD73SN5Aar4t-VWuP-UbIjLl8DYe",
      "authorship_tag": "ABX9TyNT6E7dbUzBuddlKQTrIO4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArghyaPal/Adversarial_Data_Programming/blob/master/Generalized_Adversarial_Data_Programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdUq4WsknYHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please run it once on a runtime\n",
        "!pip install kmeans-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJN9iQPsnejl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import numpy as np\n",
        "from kmeans_pytorch import kmeans, kmeans_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oAs1B2SngrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decide which device we want to run on\n",
        "ngpu = 4\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRtLbluWnjVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Hyperparameters used in this projects\n",
        "'''\n",
        "# The noise dimension for the Generator, i.e. the z dimension, sampled from a Gaussian Distribution\n",
        "latent_size = 64\n",
        "# The network layer dimension of Generator and Discriminator\n",
        "hidden_size = 128\n",
        "# The generated image size/image size. MNIST size 28 X 28 = 784\n",
        "image_size = 784\n",
        "# Number of epochs\n",
        "num_epochs = 300\n",
        "# A mini-batch size\n",
        "batch_size = 20\n",
        "# Adam learning rate\n",
        "lr = 0.0002\n",
        "# adam: decay of first order momentum of gradient\n",
        "b1 = 0.5\n",
        "b2 = 0.999\n",
        "\n",
        "# Number of classes\n",
        "nclass = 10          # For MNIST dataset, please change it for other dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8AMccZinnHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNvKg2bZnpgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_dir = 'samples'\n",
        "save_dir = 'save'\n",
        "\n",
        "# Create a directory if not exists\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Image processing\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=(0.5),   # 3 for RGB channels\n",
        "                                     std=(0.5))])\n",
        "\n",
        "# MNIST dataset\n",
        "mnist = torchvision.datasets.MNIST(root='./data/',\n",
        "                                   train=True,\n",
        "                                   transform=transform,\n",
        "                                   download=True)\n",
        "\n",
        "# Data loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBH1FU56nuFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    The labeling functions infer label of an image independently \n",
        "    (i.e. independent decision assumption) and the parameter gives relative \n",
        "    weight to each of the labeling functions based on their correctness of \n",
        "    inferred label for true class y.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X\n",
        "        Batch of real images, torch.Tensor\n",
        "    Returns\n",
        "    -------\n",
        "    y1\n",
        "        Batch of (pseudo-)ground truth labels, torch.Tensor\n",
        "    \"\"\"\n",
        "def lf1(images): \n",
        "  # fake_images is a batch of generated images from the G_image\n",
        "  cluster_centers = torch.load('/content/drive/My Drive/Colab_Notebooks/cluster_centers.pt')\n",
        "  # we use k-means (unsupervised) clustering as one labeling function\n",
        "  y = kmeans_predict(images, cluster_centers, 'cosine', device=device)\n",
        "  y = y.view(-1,1).cuda()\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmpiEm-Pnyd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.G_common = nn.Sequential(\n",
        "                              nn.Linear(latent_size, 2 * hidden_size),\n",
        "                              nn.LeakyReLU(0.2, inplace=True),\n",
        "                              nn.Linear(2 * hidden_size, 4 * hidden_size),\n",
        "                              nn.BatchNorm1d(4 * hidden_size, 0.8),\n",
        "                              nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.G_image = nn.Sequential(\n",
        "                              nn.Linear(4 * hidden_size, 8 * hidden_size),\n",
        "                              nn.BatchNorm1d(8 * hidden_size, 0.8),\n",
        "                              nn.LeakyReLU(0.2, inplace=True),\n",
        "                              nn.Linear(8 * hidden_size, image_size),\n",
        "                              nn.Tanh())\n",
        "        \n",
        "        self.G_parameter = nn.Sequential(\n",
        "                              nn.Linear(4 * hidden_size, hidden_size),\n",
        "                              nn.BatchNorm1d(hidden_size, 0.8),\n",
        "                              nn.LeakyReLU(0.2, inplace=True),\n",
        "                              nn.Linear(hidden_size, 1),\n",
        "                              # We use softmax to make the theta to be in the \n",
        "                              # range [0,1]\n",
        "                              nn.Softmax(dim=1))\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    z\n",
        "        Batch of noise vector, torch.Tensor\n",
        "    Returns\n",
        "    -------\n",
        "    X\n",
        "        Batch of images, torch.Tensor\n",
        "    y\n",
        "        Batch of a synthetic labels, torch.Tensor\n",
        "    \"\"\"\n",
        "    def forward(self, input):\n",
        "        common = self.G_common(input)\n",
        "        image = self.G_image(common)\n",
        "        labels = self.G_parameter(common)\n",
        "        return image, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB0KyRXQn3U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  '''\n",
        "  The discriminator class takes a batch of either real or generated image and \n",
        "  inferred label from Labeling Functions Block LFB(.) pairs as input.\n",
        "  And, maps that to a probability score to estimate the aforementioned \n",
        "  likelihood of the image-label pair as real labeled-image\n",
        "  '''\n",
        "  def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.D_image = nn.Sequential(\n",
        "                              nn.Linear(image_size, 4 * hidden_size),\n",
        "                              nn.LeakyReLU(0.2, inplace=True),\n",
        "                              nn.Linear(4 * hidden_size, hidden_size),\n",
        "                              nn.LeakyReLU(0.2))\n",
        "        self.D_label = nn.Sequential(\n",
        "                              nn.Linear(nclass, hidden_size),\n",
        "                              nn.LeakyReLU(0.2))\n",
        "        self.D_common = nn.Sequential(\n",
        "                              nn.Linear(2 * hidden_size, hidden_size),\n",
        "                              nn.LeakyReLU(0.2),\n",
        "                              nn.Linear(hidden_size, 1),\n",
        "                              # This will ensure the output to be in the range of [0,1]\n",
        "                              nn.Sigmoid())\n",
        "  \"\"\"Estimates the probability score as a likelihood of the input image-label pair\n",
        "  as real image-label pair.\n",
        "  This function provides a batch of probability scores, i.e. P(X, y), stored as a \n",
        "  vector P. We will use that vector to give loss signal to the Discriminator D(.) \n",
        "  and Generator G(.).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  X\n",
        "      Batch of images, torch.Tensor\n",
        "  y\n",
        "      Batch of labels, torch.Tensor\n",
        "  Returns\n",
        "  -------\n",
        "  result\n",
        "      Batch of probabilities, torch.Tensor\n",
        "  \"\"\"\n",
        "  def forward(self, image, label):\n",
        "        # image is the batch of images given to the D_image branch\n",
        "        image = self.D_image(image)\n",
        "        # label is the corresponding labels given to the D_label branch\n",
        "        label = self.D_label(label)\n",
        "        # common is the branch that concates D_image and D_label\n",
        "        common = torch.cat([image, label], 1)\n",
        "        # result is the batch of probability score\n",
        "        result = self.D_common(common)\n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BfJxljNn57_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device setting\n",
        "G = Generator().cuda()\n",
        "D = Discriminator().cuda()\n",
        "\n",
        "# Binary cross entropy loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(b1, b2))\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(b1, b2))\n",
        "\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "def reset_grad():\n",
        "    d_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu6RcKHon9m-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Statistics to be saved\n",
        "d_losses = np.zeros(num_epochs)\n",
        "g_losses = np.zeros(num_epochs)\n",
        "real_scores = np.zeros(num_epochs)\n",
        "fake_scores = np.zeros(num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ2bp6ISn_-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1263a92-c7bb-4566-b7bc-831b182626eb"
      },
      "source": [
        "# We will start Adversarial Data Programming training\n",
        "total_step = len(data_loader)\n",
        "\n",
        "# To change num_epochhs please visit the hyperparameters section\n",
        "for epoch in range(num_epochs):\n",
        "  # We will be training discriminator one time and then the generator one time\n",
        "  # using the for loop\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "\n",
        "        # Reading real MNIST images\n",
        "        images = images.view(batch_size, -1).cuda()\n",
        "        images = Variable(images)\n",
        "        # (Pseudo-)ground truth labels of images\n",
        "        original_labels = lf1(images)                         # Labeling Functions. You can create more\n",
        "        original_labels = original_labels.view(batch_size)\n",
        "        original_labels = torch.nn.functional.one_hot(original_labels.to(torch.int64), num_classes=nclass).float()      \n",
        "\n",
        "        # Labels for the discriminator. Real Labels are 1 and Fake Labels are 0\n",
        "        real_labels = torch.ones(batch_size, 1).cuda()\n",
        "        real_labels = Variable(real_labels)\n",
        "        fake_labels = torch.zeros(batch_size, 1).cuda()\n",
        "        fake_labels = Variable(fake_labels)\n",
        "\n",
        "        #######################################################################\n",
        "        ################# Training the Generator ##############################\n",
        "        #######################################################################\n",
        "        # Compute loss with fake images\n",
        "        z = torch.randn(batch_size, latent_size).cuda()\n",
        "        z = Variable(z)\n",
        "        fake_images, gen_labels = G(z)\n",
        "        gen_labels = gen_labels.view(20)\n",
        "        gen_labels = torch.nn.functional.one_hot(gen_labels.to(torch.int64), num_classes=nclass).float()\n",
        "        outputs = D(fake_images, gen_labels)\n",
        "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
        "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        # Backprop and optimize\n",
        "        # if G is trained so well, then don't update\n",
        "        reset_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "\n",
        "        #######################################################################\n",
        "        ################# Training the Discriminator ##########################\n",
        "        #######################################################################\n",
        "        '''\n",
        "        Below line of codes will train the discriminator.\n",
        "        The discriminator will take: (i) a batch of images; and (ii) a batch of labels\n",
        "        The object, i.e. outputs = D(images, original_labels), of the Discriminator class\n",
        "        We compute BCE_Loss using real images where:\n",
        "        BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
        "        Second term of the loss is always zero since real_labels == 1\n",
        "        '''\n",
        "        outputs = D(images, original_labels)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "        #######################################################################\n",
        "        '''\n",
        "        We sample z from the Isotropic Gaussian distribution\n",
        "        Compute BCELoss using fake images\n",
        "        First term of the loss is always zero since fake_labels == 0\n",
        "        '''\n",
        "        z = torch.randn(batch_size, latent_size).cuda()\n",
        "        z = Variable(z)\n",
        "        # We put that in the G_common\n",
        "        fake_images, gen_labels = G(z)\n",
        "        gen_labels = gen_labels.view(20)\n",
        "        gen_labels = torch.nn.functional.one_hot(gen_labels.to(torch.int64), num_classes=nclass).float()\n",
        "        ############################################\n",
        "        outputs = D(fake_images, gen_labels)\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        fake_score = outputs\n",
        "        # Backprop and optimize\n",
        "        # If D is trained so well, then don't update\n",
        "        d_loss = (d_loss_real + d_loss_fake)/2\n",
        "        reset_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "\n",
        "\n",
        "        #==================================================================== #\n",
        "        #                          Update Statistics                          #\n",
        "        # =================================================================== #\n",
        "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) + d_loss.data*(1./(i+1.))\n",
        "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) + g_loss.data*(1./(i+1.))\n",
        "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) + real_score.mean().data*(1./(i+1.))\n",
        "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) + fake_score.mean().data*(1./(i+1.))\n",
        "\n",
        "\n",
        "        if (i+1) % 200 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "                  .format(epoch, num_epochs, i+1, total_step, d_loss.data, g_loss.data, \n",
        "                          real_score.mean().data, fake_score.mean().data))\n",
        "            \n",
        "    # Save real images\n",
        "    if (epoch+1) == 1:\n",
        "        images = images.view(images.size(0), 1, 28, 28)\n",
        "        save_image(denorm(images.data), os.path.join(sample_dir, 'real_images.png'))\n",
        "    \n",
        "    # Save sampled images\n",
        "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
        "    print(gen_labels)\n",
        "    save_image(denorm(fake_images.data), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
        "    \n",
        "    # Save and plot Statistics\n",
        "    np.save(os.path.join(save_dir, 'd_losses.npy'), d_losses)\n",
        "    np.save(os.path.join(save_dir, 'g_losses.npy'), g_losses)\n",
        "    np.save(os.path.join(save_dir, 'fake_scores.npy'), fake_scores)\n",
        "    np.save(os.path.join(save_dir, 'real_scores.npy'), real_scores)\n",
        "    \n",
        "    plt.figure()\n",
        "    pylab.xlim(0, num_epochs + 1)\n",
        "    plt.plot(range(1, num_epochs + 1), d_losses, label='d loss')\n",
        "    plt.plot(range(1, num_epochs + 1), g_losses, label='g loss')    \n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_dir, 'loss.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    pylab.xlim(0, num_epochs + 1)\n",
        "    pylab.ylim(0, 1)\n",
        "    plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
        "    plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_dir, 'accuracy.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "    # Save model at checkpoints\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        torch.save(G.state_dict(), os.path.join(save_dir, 'G--{}.ckpt'.format(epoch+1)))\n",
        "        torch.save(D.state_dict(), os.path.join(save_dir, 'D--{}.ckpt'.format(epoch+1)))\n",
        "\n",
        "# Save the model checkpoints \n",
        "torch.save(G.state_dict(), 'G.ckpt')\n",
        "torch.save(D.state_dict(), 'D.ckpt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/300], Step [200/3000], d_loss: 0.1598, g_loss: 2.6455, D(x): 0.91, D(G(z)): 0.07\n",
            "Epoch [0/300], Step [400/3000], d_loss: 0.1094, g_loss: 2.2779, D(x): 0.96, D(G(z)): 0.10\n",
            "Epoch [0/300], Step [600/3000], d_loss: 0.2771, g_loss: 2.4786, D(x): 0.82, D(G(z)): 0.08\n",
            "Epoch [0/300], Step [800/3000], d_loss: 0.1761, g_loss: 2.6312, D(x): 0.91, D(G(z)): 0.07\n",
            "Epoch [0/300], Step [1000/3000], d_loss: 0.1636, g_loss: 2.7993, D(x): 0.91, D(G(z)): 0.06\n",
            "Epoch [0/300], Step [1200/3000], d_loss: 0.1722, g_loss: 2.8086, D(x): 0.91, D(G(z)): 0.06\n",
            "Epoch [0/300], Step [1400/3000], d_loss: 0.2849, g_loss: 2.4066, D(x): 0.82, D(G(z)): 0.09\n",
            "Epoch [0/300], Step [1600/3000], d_loss: 0.1649, g_loss: 2.5755, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [0/300], Step [1800/3000], d_loss: 0.1462, g_loss: 2.6427, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [0/300], Step [2000/3000], d_loss: 0.1667, g_loss: 2.2844, D(x): 0.91, D(G(z)): 0.11\n",
            "Epoch [0/300], Step [2200/3000], d_loss: 0.1058, g_loss: 2.5173, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [0/300], Step [2400/3000], d_loss: 0.0961, g_loss: 2.3815, D(x): 0.96, D(G(z)): 0.10\n",
            "Epoch [0/300], Step [2600/3000], d_loss: 0.1544, g_loss: 2.1211, D(x): 0.92, D(G(z)): 0.12\n",
            "Epoch [0/300], Step [2800/3000], d_loss: 0.0471, g_loss: 2.4555, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [0/300], Step [3000/3000], d_loss: 0.0498, g_loss: 2.3957, D(x): 1.00, D(G(z)): 0.09\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [1/300], Step [200/3000], d_loss: 0.1488, g_loss: 2.2370, D(x): 0.92, D(G(z)): 0.11\n",
            "Epoch [1/300], Step [400/3000], d_loss: 0.0704, g_loss: 2.0856, D(x): 1.00, D(G(z)): 0.13\n",
            "Epoch [1/300], Step [600/3000], d_loss: 0.1033, g_loss: 3.1769, D(x): 0.95, D(G(z)): 0.04\n",
            "Epoch [1/300], Step [800/3000], d_loss: 0.1182, g_loss: 2.6823, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [1/300], Step [1000/3000], d_loss: 0.1552, g_loss: 2.0007, D(x): 0.92, D(G(z)): 0.14\n",
            "Epoch [1/300], Step [1200/3000], d_loss: 0.1022, g_loss: 2.5780, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [1/300], Step [1400/3000], d_loss: 0.0823, g_loss: 2.9068, D(x): 0.96, D(G(z)): 0.06\n",
            "Epoch [1/300], Step [1600/3000], d_loss: 0.1844, g_loss: 3.1391, D(x): 0.90, D(G(z)): 0.05\n",
            "Epoch [1/300], Step [1800/3000], d_loss: 0.1576, g_loss: 2.5595, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [1/300], Step [2000/3000], d_loss: 0.2644, g_loss: 2.3831, D(x): 0.82, D(G(z)): 0.10\n",
            "Epoch [1/300], Step [2200/3000], d_loss: 0.2993, g_loss: 2.6915, D(x): 0.82, D(G(z)): 0.07\n",
            "Epoch [1/300], Step [2400/3000], d_loss: 0.0953, g_loss: 2.5980, D(x): 0.96, D(G(z)): 0.08\n",
            "Epoch [1/300], Step [2600/3000], d_loss: 0.0913, g_loss: 2.7840, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [1/300], Step [2800/3000], d_loss: 0.0965, g_loss: 2.8774, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [1/300], Step [3000/3000], d_loss: 0.1887, g_loss: 2.8503, D(x): 0.90, D(G(z)): 0.06\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [2/300], Step [200/3000], d_loss: 0.2048, g_loss: 2.4159, D(x): 0.87, D(G(z)): 0.09\n",
            "Epoch [2/300], Step [400/3000], d_loss: 0.2312, g_loss: 2.6763, D(x): 0.86, D(G(z)): 0.07\n",
            "Epoch [2/300], Step [600/3000], d_loss: 0.0302, g_loss: 2.8415, D(x): 1.00, D(G(z)): 0.06\n",
            "Epoch [2/300], Step [800/3000], d_loss: 0.1754, g_loss: 2.2958, D(x): 0.91, D(G(z)): 0.11\n",
            "Epoch [2/300], Step [1000/3000], d_loss: 0.0260, g_loss: 2.9441, D(x): 1.00, D(G(z)): 0.05\n",
            "Epoch [2/300], Step [1200/3000], d_loss: 0.1726, g_loss: 2.3280, D(x): 0.91, D(G(z)): 0.10\n",
            "Epoch [2/300], Step [1400/3000], d_loss: 0.1018, g_loss: 2.8065, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [2/300], Step [1600/3000], d_loss: 0.1713, g_loss: 2.7067, D(x): 0.91, D(G(z)): 0.06\n",
            "Epoch [2/300], Step [1800/3000], d_loss: 0.1024, g_loss: 2.7637, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [2/300], Step [2000/3000], d_loss: 0.1794, g_loss: 2.8969, D(x): 0.90, D(G(z)): 0.06\n",
            "Epoch [2/300], Step [2200/3000], d_loss: 0.2363, g_loss: 2.6306, D(x): 0.86, D(G(z)): 0.07\n",
            "Epoch [2/300], Step [2400/3000], d_loss: 0.1639, g_loss: 2.6069, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [2/300], Step [2600/3000], d_loss: 0.0479, g_loss: 2.4241, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [2/300], Step [2800/3000], d_loss: 0.1779, g_loss: 2.7263, D(x): 0.91, D(G(z)): 0.07\n",
            "Epoch [2/300], Step [3000/3000], d_loss: 0.2268, g_loss: 2.6332, D(x): 0.86, D(G(z)): 0.07\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [3/300], Step [200/3000], d_loss: 0.2256, g_loss: 2.6116, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [3/300], Step [400/3000], d_loss: 0.1530, g_loss: 2.5959, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [3/300], Step [600/3000], d_loss: 0.1053, g_loss: 2.5062, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [3/300], Step [800/3000], d_loss: 0.1108, g_loss: 2.3495, D(x): 0.95, D(G(z)): 0.10\n",
            "Epoch [3/300], Step [1000/3000], d_loss: 0.1011, g_loss: 2.7076, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [3/300], Step [1200/3000], d_loss: 0.1656, g_loss: 2.5322, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [3/300], Step [1400/3000], d_loss: 0.1714, g_loss: 2.8323, D(x): 0.91, D(G(z)): 0.06\n",
            "Epoch [3/300], Step [1600/3000], d_loss: 0.0997, g_loss: 2.8337, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [3/300], Step [1800/3000], d_loss: 0.1103, g_loss: 2.3170, D(x): 0.95, D(G(z)): 0.10\n",
            "Epoch [3/300], Step [2000/3000], d_loss: 0.1690, g_loss: 2.6490, D(x): 0.91, D(G(z)): 0.07\n",
            "Epoch [3/300], Step [2200/3000], d_loss: 0.0469, g_loss: 2.4571, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [3/300], Step [2400/3000], d_loss: 0.1703, g_loss: 2.7584, D(x): 0.91, D(G(z)): 0.06\n",
            "Epoch [3/300], Step [2600/3000], d_loss: 0.1712, g_loss: 2.4037, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [3/300], Step [2800/3000], d_loss: 0.2301, g_loss: 2.5008, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [3/300], Step [3000/3000], d_loss: 0.1075, g_loss: 2.6174, D(x): 0.95, D(G(z)): 0.08\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [4/300], Step [200/3000], d_loss: 0.1088, g_loss: 2.5004, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [4/300], Step [400/3000], d_loss: 0.1048, g_loss: 2.5442, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [4/300], Step [600/3000], d_loss: 0.0926, g_loss: 2.4691, D(x): 0.96, D(G(z)): 0.08\n",
            "Epoch [4/300], Step [800/3000], d_loss: 0.1136, g_loss: 2.3503, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [4/300], Step [1000/3000], d_loss: 0.2311, g_loss: 2.5132, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [4/300], Step [1200/3000], d_loss: 0.2336, g_loss: 2.5685, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [4/300], Step [1400/3000], d_loss: 0.1713, g_loss: 2.5530, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [4/300], Step [1600/3000], d_loss: 0.1759, g_loss: 2.5740, D(x): 0.91, D(G(z)): 0.07\n",
            "Epoch [4/300], Step [1800/3000], d_loss: 0.0421, g_loss: 2.5226, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [4/300], Step [2000/3000], d_loss: 0.2871, g_loss: 2.4218, D(x): 0.82, D(G(z)): 0.09\n",
            "Epoch [4/300], Step [2200/3000], d_loss: 0.1033, g_loss: 2.5426, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [4/300], Step [2400/3000], d_loss: 0.1031, g_loss: 2.6757, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [4/300], Step [2600/3000], d_loss: 0.2270, g_loss: 2.5422, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [4/300], Step [2800/3000], d_loss: 0.2323, g_loss: 2.6616, D(x): 0.86, D(G(z)): 0.07\n",
            "Epoch [4/300], Step [3000/3000], d_loss: 0.1059, g_loss: 2.4728, D(x): 0.95, D(G(z)): 0.08\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [5/300], Step [200/3000], d_loss: 0.2362, g_loss: 2.6821, D(x): 0.86, D(G(z)): 0.07\n",
            "Epoch [5/300], Step [400/3000], d_loss: 0.1046, g_loss: 2.6883, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [5/300], Step [600/3000], d_loss: 0.1700, g_loss: 2.5304, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [5/300], Step [800/3000], d_loss: 0.0516, g_loss: 2.3537, D(x): 1.00, D(G(z)): 0.10\n",
            "Epoch [5/300], Step [1000/3000], d_loss: 0.2907, g_loss: 2.4322, D(x): 0.82, D(G(z)): 0.09\n",
            "Epoch [5/300], Step [1200/3000], d_loss: 0.2904, g_loss: 2.3931, D(x): 0.82, D(G(z)): 0.09\n",
            "Epoch [5/300], Step [1400/3000], d_loss: 0.2245, g_loss: 2.3928, D(x): 0.86, D(G(z)): 0.09\n",
            "Epoch [5/300], Step [1600/3000], d_loss: 0.1036, g_loss: 2.6133, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [5/300], Step [1800/3000], d_loss: 0.2270, g_loss: 2.4257, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [5/300], Step [2000/3000], d_loss: 0.1681, g_loss: 2.6360, D(x): 0.91, D(G(z)): 0.07\n",
            "Epoch [5/300], Step [2200/3000], d_loss: 0.0517, g_loss: 2.3209, D(x): 1.00, D(G(z)): 0.10\n",
            "Epoch [5/300], Step [2400/3000], d_loss: 0.1035, g_loss: 2.4898, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [5/300], Step [2600/3000], d_loss: 0.0479, g_loss: 2.4139, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [5/300], Step [2800/3000], d_loss: 0.2952, g_loss: 2.5112, D(x): 0.82, D(G(z)): 0.08\n",
            "Epoch [5/300], Step [3000/3000], d_loss: 0.1084, g_loss: 2.3883, D(x): 0.95, D(G(z)): 0.09\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [6/300], Step [200/3000], d_loss: 0.0979, g_loss: 2.8160, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [6/300], Step [400/3000], d_loss: 0.1601, g_loss: 2.4972, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [6/300], Step [600/3000], d_loss: 0.1663, g_loss: 2.2088, D(x): 0.91, D(G(z)): 0.11\n",
            "Epoch [6/300], Step [800/3000], d_loss: 0.1655, g_loss: 2.4623, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [6/300], Step [1000/3000], d_loss: 0.1679, g_loss: 2.4257, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [6/300], Step [1200/3000], d_loss: 0.1642, g_loss: 2.3616, D(x): 0.91, D(G(z)): 0.10\n",
            "Epoch [6/300], Step [1400/3000], d_loss: 0.1634, g_loss: 2.3988, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [6/300], Step [1600/3000], d_loss: 0.0419, g_loss: 2.5298, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [6/300], Step [1800/3000], d_loss: 0.2184, g_loss: 2.5820, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [6/300], Step [2000/3000], d_loss: 0.1733, g_loss: 2.3628, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [6/300], Step [2200/3000], d_loss: 0.2313, g_loss: 2.5754, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [6/300], Step [2400/3000], d_loss: 0.0406, g_loss: 2.5549, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [6/300], Step [2600/3000], d_loss: 0.2286, g_loss: 2.5340, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [6/300], Step [2800/3000], d_loss: 0.0442, g_loss: 2.4320, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [6/300], Step [3000/3000], d_loss: 0.1701, g_loss: 2.3913, D(x): 0.91, D(G(z)): 0.09\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [7/300], Step [200/3000], d_loss: 0.1675, g_loss: 2.5712, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [7/300], Step [400/3000], d_loss: 0.1706, g_loss: 2.5187, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [7/300], Step [600/3000], d_loss: 0.1022, g_loss: 2.8719, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [7/300], Step [800/3000], d_loss: 0.0418, g_loss: 2.5082, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [7/300], Step [1000/3000], d_loss: 0.2864, g_loss: 2.3356, D(x): 0.82, D(G(z)): 0.10\n",
            "Epoch [7/300], Step [1200/3000], d_loss: 0.1699, g_loss: 2.2784, D(x): 0.91, D(G(z)): 0.10\n",
            "Epoch [7/300], Step [1400/3000], d_loss: 0.0435, g_loss: 2.4932, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [7/300], Step [1600/3000], d_loss: 0.1031, g_loss: 2.4545, D(x): 0.96, D(G(z)): 0.09\n",
            "Epoch [7/300], Step [1800/3000], d_loss: 0.2398, g_loss: 2.6673, D(x): 0.86, D(G(z)): 0.07\n",
            "Epoch [7/300], Step [2000/3000], d_loss: 0.2296, g_loss: 2.5120, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [7/300], Step [2200/3000], d_loss: 0.0355, g_loss: 2.6400, D(x): 1.00, D(G(z)): 0.07\n",
            "Epoch [7/300], Step [2400/3000], d_loss: 0.0449, g_loss: 2.4793, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [7/300], Step [2600/3000], d_loss: 0.0546, g_loss: 2.2812, D(x): 1.00, D(G(z)): 0.10\n",
            "Epoch [7/300], Step [2800/3000], d_loss: 0.1050, g_loss: 2.5446, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [7/300], Step [3000/3000], d_loss: 0.1633, g_loss: 2.4580, D(x): 0.91, D(G(z)): 0.09\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [8/300], Step [200/3000], d_loss: 0.1091, g_loss: 2.3981, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [8/300], Step [400/3000], d_loss: 0.1046, g_loss: 2.4630, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [8/300], Step [600/3000], d_loss: 0.1032, g_loss: 2.9544, D(x): 0.95, D(G(z)): 0.05\n",
            "Epoch [8/300], Step [800/3000], d_loss: 0.1073, g_loss: 2.8592, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [8/300], Step [1000/3000], d_loss: 0.1660, g_loss: 2.4298, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [8/300], Step [1200/3000], d_loss: 0.0470, g_loss: 2.4385, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [8/300], Step [1400/3000], d_loss: 0.0313, g_loss: 2.7998, D(x): 1.00, D(G(z)): 0.06\n",
            "Epoch [8/300], Step [1600/3000], d_loss: 0.1097, g_loss: 2.2759, D(x): 0.96, D(G(z)): 0.10\n",
            "Epoch [8/300], Step [1800/3000], d_loss: 0.2295, g_loss: 2.3934, D(x): 0.86, D(G(z)): 0.09\n",
            "Epoch [8/300], Step [2000/3000], d_loss: 0.1673, g_loss: 2.5548, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [8/300], Step [2200/3000], d_loss: 0.1108, g_loss: 2.2806, D(x): 0.96, D(G(z)): 0.10\n",
            "Epoch [8/300], Step [2400/3000], d_loss: 0.1042, g_loss: 2.5559, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [8/300], Step [2600/3000], d_loss: 0.0990, g_loss: 2.7228, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [8/300], Step [2800/3000], d_loss: 0.3426, g_loss: 2.3429, D(x): 0.77, D(G(z)): 0.10\n",
            "Epoch [8/300], Step [3000/3000], d_loss: 0.2131, g_loss: 2.1441, D(x): 0.88, D(G(z)): 0.14\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [9/300], Step [200/3000], d_loss: 0.1627, g_loss: 2.3797, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [9/300], Step [400/3000], d_loss: 0.3636, g_loss: 2.5593, D(x): 0.77, D(G(z)): 0.08\n",
            "Epoch [9/300], Step [600/3000], d_loss: 0.1075, g_loss: 2.4228, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [9/300], Step [800/3000], d_loss: 0.1112, g_loss: 2.2481, D(x): 0.96, D(G(z)): 0.11\n",
            "Epoch [9/300], Step [1000/3000], d_loss: 0.1048, g_loss: 2.4219, D(x): 0.96, D(G(z)): 0.09\n",
            "Epoch [9/300], Step [1200/3000], d_loss: 0.1711, g_loss: 2.4706, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [9/300], Step [1400/3000], d_loss: 0.1767, g_loss: 2.8527, D(x): 0.91, D(G(z)): 0.06\n",
            "Epoch [9/300], Step [1600/3000], d_loss: 0.1073, g_loss: 2.4025, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [9/300], Step [1800/3000], d_loss: 0.2921, g_loss: 2.4422, D(x): 0.82, D(G(z)): 0.09\n",
            "Epoch [9/300], Step [2000/3000], d_loss: 0.1079, g_loss: 2.4697, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [9/300], Step [2200/3000], d_loss: 0.1490, g_loss: 2.3418, D(x): 0.91, D(G(z)): 0.10\n",
            "Epoch [9/300], Step [2400/3000], d_loss: 0.1697, g_loss: 2.4949, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [9/300], Step [2600/3000], d_loss: 0.0522, g_loss: 2.3050, D(x): 1.00, D(G(z)): 0.10\n",
            "Epoch [9/300], Step [2800/3000], d_loss: 0.0985, g_loss: 2.7898, D(x): 0.95, D(G(z)): 0.06\n",
            "Epoch [9/300], Step [3000/3000], d_loss: 0.2877, g_loss: 2.4319, D(x): 0.82, D(G(z)): 0.09\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [10/300], Step [200/3000], d_loss: 0.3017, g_loss: 2.6686, D(x): 0.81, D(G(z)): 0.07\n",
            "Epoch [10/300], Step [400/3000], d_loss: 0.1038, g_loss: 2.5301, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [10/300], Step [600/3000], d_loss: 0.1028, g_loss: 2.6240, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [10/300], Step [800/3000], d_loss: 0.1740, g_loss: 2.3923, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [10/300], Step [1000/3000], d_loss: 0.1209, g_loss: 2.3537, D(x): 0.95, D(G(z)): 0.10\n",
            "Epoch [10/300], Step [1200/3000], d_loss: 0.2260, g_loss: 2.5950, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [10/300], Step [1400/3000], d_loss: 0.2349, g_loss: 2.5540, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [10/300], Step [1600/3000], d_loss: 0.0407, g_loss: 2.5484, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [10/300], Step [1800/3000], d_loss: 0.2359, g_loss: 2.4629, D(x): 0.86, D(G(z)): 0.09\n",
            "Epoch [10/300], Step [2000/3000], d_loss: 0.1016, g_loss: 2.6305, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [10/300], Step [2200/3000], d_loss: 0.1737, g_loss: 2.5042, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [10/300], Step [2400/3000], d_loss: 0.2292, g_loss: 2.5361, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [10/300], Step [2600/3000], d_loss: 0.2265, g_loss: 2.5044, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [10/300], Step [2800/3000], d_loss: 0.1116, g_loss: 2.4353, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [10/300], Step [3000/3000], d_loss: 0.0480, g_loss: 2.3767, D(x): 1.00, D(G(z)): 0.09\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [11/300], Step [200/3000], d_loss: 0.1638, g_loss: 2.4196, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [11/300], Step [400/3000], d_loss: 0.1660, g_loss: 2.3896, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [11/300], Step [600/3000], d_loss: 0.1657, g_loss: 2.4413, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [11/300], Step [800/3000], d_loss: 0.2296, g_loss: 2.4118, D(x): 0.86, D(G(z)): 0.09\n",
            "Epoch [11/300], Step [1000/3000], d_loss: 0.1645, g_loss: 2.4788, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [11/300], Step [1200/3000], d_loss: 0.1064, g_loss: 2.4284, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [11/300], Step [1400/3000], d_loss: 0.3255, g_loss: 2.9882, D(x): 0.81, D(G(z)): 0.05\n",
            "Epoch [11/300], Step [1600/3000], d_loss: 0.1694, g_loss: 2.4800, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [11/300], Step [1800/3000], d_loss: 0.2985, g_loss: 2.5768, D(x): 0.82, D(G(z)): 0.08\n",
            "Epoch [11/300], Step [2000/3000], d_loss: 0.1632, g_loss: 2.5399, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [11/300], Step [2200/3000], d_loss: 0.2255, g_loss: 2.3891, D(x): 0.86, D(G(z)): 0.09\n",
            "Epoch [11/300], Step [2400/3000], d_loss: 0.0573, g_loss: 2.2717, D(x): 1.00, D(G(z)): 0.11\n",
            "Epoch [11/300], Step [2600/3000], d_loss: 0.1210, g_loss: 2.0922, D(x): 0.96, D(G(z)): 0.13\n",
            "Epoch [11/300], Step [2800/3000], d_loss: 0.1068, g_loss: 2.4845, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [11/300], Step [3000/3000], d_loss: 0.1065, g_loss: 2.3897, D(x): 0.96, D(G(z)): 0.09\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [12/300], Step [200/3000], d_loss: 0.2289, g_loss: 2.6919, D(x): 0.86, D(G(z)): 0.07\n",
            "Epoch [12/300], Step [400/3000], d_loss: 0.1686, g_loss: 2.5524, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [12/300], Step [600/3000], d_loss: 0.2287, g_loss: 2.4360, D(x): 0.86, D(G(z)): 0.09\n",
            "Epoch [12/300], Step [800/3000], d_loss: 0.1733, g_loss: 2.5539, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [12/300], Step [1000/3000], d_loss: 0.1801, g_loss: 2.6569, D(x): 0.91, D(G(z)): 0.07\n",
            "Epoch [12/300], Step [1200/3000], d_loss: 0.1704, g_loss: 2.6119, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [12/300], Step [1400/3000], d_loss: 0.1133, g_loss: 2.2164, D(x): 0.96, D(G(z)): 0.11\n",
            "Epoch [12/300], Step [1600/3000], d_loss: 0.1750, g_loss: 2.3122, D(x): 0.91, D(G(z)): 0.10\n",
            "Epoch [12/300], Step [1800/3000], d_loss: 0.1647, g_loss: 2.4506, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [12/300], Step [2000/3000], d_loss: 0.1674, g_loss: 2.4950, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [12/300], Step [2200/3000], d_loss: 0.3651, g_loss: 2.5575, D(x): 0.77, D(G(z)): 0.08\n",
            "Epoch [12/300], Step [2400/3000], d_loss: 0.1631, g_loss: 2.5375, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [12/300], Step [2600/3000], d_loss: 0.1716, g_loss: 2.5960, D(x): 0.91, D(G(z)): 0.07\n",
            "Epoch [12/300], Step [2800/3000], d_loss: 0.1069, g_loss: 2.4185, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [12/300], Step [3000/3000], d_loss: 0.1063, g_loss: 2.5463, D(x): 0.95, D(G(z)): 0.08\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [13/300], Step [200/3000], d_loss: 0.0487, g_loss: 2.3923, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [13/300], Step [400/3000], d_loss: 0.1062, g_loss: 2.5165, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [13/300], Step [600/3000], d_loss: 0.1681, g_loss: 2.7512, D(x): 0.91, D(G(z)): 0.06\n",
            "Epoch [13/300], Step [800/3000], d_loss: 0.1065, g_loss: 2.6750, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [13/300], Step [1000/3000], d_loss: 0.0441, g_loss: 2.5017, D(x): 1.00, D(G(z)): 0.08\n",
            "Epoch [13/300], Step [1200/3000], d_loss: 0.2268, g_loss: 2.5443, D(x): 0.86, D(G(z)): 0.08\n",
            "Epoch [13/300], Step [1400/3000], d_loss: 0.1696, g_loss: 2.5567, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [13/300], Step [1600/3000], d_loss: 0.1671, g_loss: 2.4739, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [13/300], Step [1800/3000], d_loss: 0.0451, g_loss: 2.4975, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [13/300], Step [2000/3000], d_loss: 0.1699, g_loss: 2.3691, D(x): 0.91, D(G(z)): 0.09\n",
            "Epoch [13/300], Step [2200/3000], d_loss: 0.1712, g_loss: 2.3363, D(x): 0.91, D(G(z)): 0.10\n",
            "Epoch [13/300], Step [2400/3000], d_loss: 0.0356, g_loss: 2.6865, D(x): 1.00, D(G(z)): 0.07\n",
            "Epoch [13/300], Step [2600/3000], d_loss: 0.1691, g_loss: 2.2233, D(x): 0.91, D(G(z)): 0.11\n",
            "Epoch [13/300], Step [2800/3000], d_loss: 0.1056, g_loss: 2.5576, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [13/300], Step [3000/3000], d_loss: 0.0514, g_loss: 2.3244, D(x): 1.00, D(G(z)): 0.10\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "Epoch [14/300], Step [200/3000], d_loss: 0.1055, g_loss: 2.4837, D(x): 0.95, D(G(z)): 0.08\n",
            "Epoch [14/300], Step [400/3000], d_loss: 0.1028, g_loss: 2.3930, D(x): 0.96, D(G(z)): 0.09\n",
            "Epoch [14/300], Step [600/3000], d_loss: 0.1632, g_loss: 2.5169, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [14/300], Step [800/3000], d_loss: 0.2810, g_loss: 2.3607, D(x): 0.82, D(G(z)): 0.10\n",
            "Epoch [14/300], Step [1000/3000], d_loss: 0.1026, g_loss: 2.6494, D(x): 0.95, D(G(z)): 0.07\n",
            "Epoch [14/300], Step [1200/3000], d_loss: 0.0445, g_loss: 2.4637, D(x): 1.00, D(G(z)): 0.09\n",
            "Epoch [14/300], Step [1400/3000], d_loss: 0.1083, g_loss: 2.6108, D(x): 0.95, D(G(z)): 0.07\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}